# Student Performance Classification

End-to-end ML pipeline to classify students into: High Performer, Average Performer, Needs Improvement. It includes data generation, preprocessing, EDA, model training and evaluation, model comparison, and a CLI for inference.

## Dataset
- Default: synthetic dataset generated by `src/generate_dataset.py`
- Features: `MST_Score`, `Quiz_Avg`, `Attendance`, `Assignment_Score`
- Target: `Category` with classes [High Performer, Average Performer, Needs Improvement]

## Preprocessing
- Handle missing values using mean imputation (SimpleImputer)
- Scale numeric features (StandardScaler)
- Encode labels (LabelEncoder)

## Models
- Logistic Regression, Decision Tree, Random Forest, KNN, SVC
- Optional: XGBoost (auto-enabled if package available)
- 5-fold cross-validation for comparison; optional light GridSearch for top models (`--tune`)

## Evaluation & Visualizations
Saved under `outputs/` after training:
- `confusion_matrix.png` (best model)
- `feature_distributions.png`
- `correlation_heatmap.png`
- `attendance_vs_performance.png`
- `model_comparison_accuracy.png`
- `model_comparison_f1.png`
- `roc_curves.png` (if model provides probabilities)
- `model_metrics.csv` (per-model metrics)

## Quick start (Windows PowerShell)

```powershell
# Clone this repo by using the terminal
git clone https://github.com/naveedqadir/SmartEdu_Classifier.git

# Change to the cloned directory
cd SmartEdu_Classifier

# Create a venv
python3 -m venv .venv

# Activate the venv
.\.venv\Scripts\Activate.ps1

# Install dependencies (if not already installed)
pip install -r requirements.txt

# Generate dataset
python src/generate_dataset.py

# Train and evaluate models (adds visuals + saves best model)
python src/train.py --data data/students.csv --test-size 0.25 --seed 42

# Optional: enable light hyperparameter tuning
python src/train.py --tune
```

Artifacts:
- Best model and preprocessors: `models/best_model.joblib`
- Example outputs: see `outputs/` folder

## Use the Notebook
Open `notebooks/student_performance.ipynb` and run cells top-to-bottom:
- Cells 1–3: imports, load data, quick EDA (dists + correlation)
- Cell 4: overview of the training steps
- Cell 5: preprocessing + train/test split (impute, scale, label-encode)
- Cell 6: train multiple models, compute metrics and 5-fold CV
- Cell 7: comparison plots (accuracy/F1) and attendance vs performance
- Cell 8: best-model evaluation (report + confusion matrix + ROC), save artifacts to `../models/best_model.joblib`

The notebook mirrors `src/train.py` and is safe to re-run. Figures display inline; artifacts are saved relative to the notebook location.

## Prediction CLI

Batch CSV prediction:

```powershell
python src/predict.py --input data/students.csv --output outputs/predictions.csv
```

Single-sample prediction:

```powershell
python src/predict.py --mst 72.5 --quiz 81.1 --attendance 95.0 --assignment 78.9
```

Include class probabilities (if supported by the model):

```powershell
python src/predict.py --input data/students.csv --output outputs/predictions.csv --proba
```

CLI help:

```powershell
python src/predict.py -h
```

## Project Structure
- `src/generate_dataset.py` – create synthetic dataset
- `src/train.py` – preprocessing, training, eval, visuals, save best model
- `src/predict.py` – CLI for inference (CSV or single sample)
- `notebooks/student_performance.ipynb` – optional EDA notebook
- `data/` – dataset CSV
- `models/` – saved joblib artifacts
- `outputs/` – plots and reports

## Flow (Text Diagram)
Start → Data Collection → Preprocessing → EDA → Model Building → Model Evaluation → Best Model Selection → Deployment/Report → End

## Notes
- This repo targets Windows/PowerShell. Activate your venv each session.
- If XGBoost is not available, training will skip it automatically.
